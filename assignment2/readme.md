Remark:

- Q1: Fully-connected Neural Network
  - `forward` and `backward` function (for each layer), which can automatically compute loss and gradient for deep neural nets.
  - (Similar as in assignment 1) Manual forward and backward pass for 2-layer neural network
  - Manual forward and backward pass for general (arbitrary number of hidden layers) neural network
  - Various parameter updates: Momentum, RMSProp, Adam
